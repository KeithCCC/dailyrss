{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class rsss_feed:\n",
    "    def __init__(self, source_site_name, title, url, uri, created_date):\n",
    "        self.source_site_name = source_site_name\n",
    "        self.title = title\n",
    "        self.url = url\n",
    "        self.uri = uri\n",
    "        self.created_date = created_date\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"rsss_feed(title={self.title}, url={self.url})\"\n",
    "\n",
    "class source_site:\n",
    "    def __init__(self, title, url):\n",
    "        self.title = title\n",
    "        self.url = url\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"source_site(titel={self.title}, url={self.url})\"\n",
    "    \n",
    "    def add_rss_feed(self, rss_feed):\n",
    "        self.children.append(rss_feed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = source_site(\"source\", \"@IT\", \"https://atmarkit.itmedia.co.jp/\", \"https://atmarkit.itmedia.co.jp/\", \"Atmark IT\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@IT\n"
     ]
    }
   ],
   "source": [
    "print(source.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "initial_data = [[0,\"source\", \"@IT\", \"\\\"https://atmarkit.itmedia.co.jp/\\\"\", \"\\\"https://atmarkit.itmedia.co.jp/\\\"\", \"Atmark IT\"]]\n",
    "\n",
    "df = pd.DataFrame(initial_data, columns=[\"uid\", \"Type\", \"Title\", \"URL\", \"URI\", \"Description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>Type</th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>URI</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>source</td>\n",
       "      <td>@IT</td>\n",
       "      <td>\"https://atmarkit.itmedia.co.jp/\"</td>\n",
       "      <td>\"https://atmarkit.itmedia.co.jp/\"</td>\n",
       "      <td>Atmark IT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid    Type Title                                URL  \\\n",
       "0    0  source   @IT  \"https://atmarkit.itmedia.co.jp/\"   \n",
       "\n",
       "                                 URI Description  \n",
       "0  \"https://atmarkit.itmedia.co.jp/\"   Atmark IT  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringA = df[df['uid'] == 0]['URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [[3,2,1,0]]\n",
    "\n",
    "df1 = pd.DataFrame(data1, columns=[\"A\", \"B\", \"C\", \"D\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2\n",
      "Name: B, dtype: object\n"
     ]
    }
   ],
   "source": [
    "strA = df1[df1['A'] == 3]['B']\n",
    "print (strA.astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "strB = df1.query('A == 3')['B']\n",
    "elementB = df1.loc[0, 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(elementB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# initial_data = [[0,\"source\", \"@IT\", \"\\\"https://atmarkit.itmedia.co.jp/\\\"\", \"\\\"https://atmarkit.itmedia.co.jp/\\\"\", \"Atmark IT\"]]\n",
    "initial_data = [[0,\"source\", \"@IT\", \"https://atmarkit.itmedia.co.jp/\", \"https://atmarkit.itmedia.co.jp/\", \"Atmark IT\"]]\n",
    "  \n",
    "    \n",
    "sites_df = pd.DataFrame(initial_data, columns=[\"uid\", \"Type\", \"Title\", \"URL\", \"URI\", \"Description\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_site_url=\"https://akiba-pc.watch.impress.co.jp/\"\n",
    "new_row = pd.DataFrame({'URL': [new_site_url], 'URI': [new_site_url]})\n",
    "sites_df= pd.concat([sites_df, new_row], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def sample_df():\n",
    "    initial_data = [[0,\"source\", \"@IT\", \"https://atmarkit.itmedia.co.jp/\", \"https://atmarkit.itmedia.co.jp/\", \"Atmark IT\"]]\n",
    "    sample_df = pd.DataFrame(initial_data, columns=[\"uid\", \"Type\", \"Title\", \"URL\", \"URI\", \"Description\"])\n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"default.json\"\n",
    "if not os.path.exists(filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        sites_df.to_json(filename, orient='records')\n",
    "else:\n",
    "    sites_df = pd.read_json(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-25\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Date string\n",
    "date_str = \"Thu, 25 Jul 2024 10:00:00 +0900\"\n",
    "\n",
    "# Parse the date string\n",
    "date_object = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %z')\n",
    "\n",
    "# Print the resulting datetime object\n",
    "print(date_object.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "# String variables\n",
    "text = \"Hello, World!\"\n",
    "color = \"blue\"\n",
    "font_size = \"24px\"\n",
    "\n",
    "# Create the HTML string with the variables\n",
    "html_str = f\"<p style='font-size:{font_size}; color:{color};'>{text}</p>\"\n",
    "\n",
    "# Display the styled text in Streamlit\n",
    "st.markdown(html_str, unsafe_allow_html=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "website_url = \"https://atmarkit.itmedia.co.jp/\"\n",
    "\n",
    "response = requests.get(website_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "rss_urls = []\n",
    "for link in soup.find_all('link', type='application/rss+xml'):\n",
    "    rss_urls.append(link.get('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://rss.itmedia.co.jp/rss/0.91/ait.xml',\n",
       " 'https://rss.itmedia.co.jp/rss/1.0/ait.xml',\n",
       " 'https://rss.itmedia.co.jp/rss/2.0/ait.xml']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rss_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "url = \"https://news.yahoo.co.jp/rss/topics/top-picks.xml\"\n",
    "\n",
    "feed = feedparser.parse(url)\n",
    "for entry in feed.entries:\n",
    "    if 'published' in entry:\n",
    "        print(entry.published)\n",
    "    print(entry.title)\n",
    "    print(entry.link)\n",
    "    #print(entry.summary)\n",
    "    print('---------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from xml.etree import ElementTree\n",
    "import streamlit  as st\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "filename_news= \"newsfeed.json\"\n",
    "news_df = pd.read_json(filename_news)\n",
    "\n",
    "print(news_df)\n",
    "\n",
    "rss_feeds = [news_df.loc[1, 'URL']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://news.yahoo.co.jp/rss/topics/top-picks.xml']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rss_feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue, 13 Aug 2024 10:09:08 GMT\n",
      "東海道新幹線16-17日運休の可能性\n",
      "https://news.yahoo.co.jp/pickup/6510601?source=rss\n",
      "---------------------------------\n",
      "Tue, 13 Aug 2024 08:05:35 GMT\n",
      "全国的に来週も厳しい暑さ続く\n",
      "https://news.yahoo.co.jp/pickup/6510580?source=rss\n",
      "---------------------------------\n",
      "Tue, 13 Aug 2024 09:26:07 GMT\n",
      "4歳泣いて海へ 米軍に狙われた船\n",
      "https://news.yahoo.co.jp/pickup/6510595?source=rss\n",
      "---------------------------------\n",
      "Tue, 13 Aug 2024 11:22:41 GMT\n",
      "保育園が突然休園「ありえない」\n",
      "https://news.yahoo.co.jp/pickup/6510607?source=rss\n",
      "---------------------------------\n",
      "Tue, 13 Aug 2024 11:15:56 GMT\n",
      "「貯金は150万円」新富裕層の実態\n",
      "https://news.yahoo.co.jp/pickup/6510606?source=rss\n",
      "---------------------------------\n",
      "Tue, 13 Aug 2024 11:13:22 GMT\n",
      "高温の甲子園 球児相次ぎ足に異変\n",
      "https://news.yahoo.co.jp/pickup/6510609?source=rss\n",
      "---------------------------------\n",
      "Tue, 13 Aug 2024 10:17:53 GMT\n",
      "無課金おじさん「心の中では嵐」\n",
      "https://news.yahoo.co.jp/pickup/6510603?source=rss\n",
      "---------------------------------\n",
      "Tue, 13 Aug 2024 11:59:44 GMT\n",
      "梅宮アンナ、乳がんり患を報告\n",
      "https://news.yahoo.co.jp/pickup/6510610?source=rss\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "for item in rss_feeds:\n",
    "    feed = feedparser.parse(item)\n",
    "    # st.text(rss_feeds)\n",
    "    # st.text(len(feed))\n",
    "    # st.text(feed)\n",
    "    for entry in feed.entries:\n",
    "        if 'published' in entry:\n",
    "            print(entry.published)\n",
    "        print(entry.title)\n",
    "        print(entry.link)\n",
    "        print('---------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add news rss from site\n",
      "   uid    Type                                              Title  \\\n",
      "0  0.0  source                                                @IT   \n",
      "1  NaN    None  https://news.yahoo.co.jp/rss/topics/top-picks.xml   \n",
      "\n",
      "                                                 URL  \\\n",
      "0                    https://atmarkit.itmedia.co.jp/   \n",
      "1  https://news.yahoo.co.jp/rss/topics/top-picks.xml   \n",
      "\n",
      "                                                 URI Description  \n",
      "0                    https://atmarkit.itmedia.co.jp/   Atmark IT  \n",
      "1  https://news.yahoo.co.jp/rss/topics/top-picks.xml              \n",
      "0    https://atmarkit.itmedia.co.jp/\n",
      "Name: URL, dtype: object\n",
      "Add news rss\n",
      "   uid  Type                                              Title  \\\n",
      "1  NaN  None  https://news.yahoo.co.jp/rss/topics/top-picks.xml   \n",
      "\n",
      "                                                 URL  \\\n",
      "1  https://news.yahoo.co.jp/rss/topics/top-picks.xml   \n",
      "\n",
      "                                                 URI Description  \n",
      "1  https://news.yahoo.co.jp/rss/topics/top-picks.xml              \n"
     ]
    }
   ],
   "source": [
    "from xml.etree import ElementTree\n",
    "import streamlit  as st\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "filename_news= \"newsfeed.json\"\n",
    "news_df = pd.read_json(filename_news)\n",
    "\n",
    "print(\"Add news rss from site\")\n",
    "\n",
    "print(news_df)\n",
    "# print(news_df.query('Type == source')['url'])\n",
    "print(news_df[news_df['Type'] == 'source']['URL'])\n",
    "\n",
    "print(\"Add news rss\")\n",
    "print(news_df[news_df['Type'] != 'source'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source @IT\n",
      "0\n",
      "None https://news.yahoo.co.jp/rss/topics/top-picks.xml\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "news_df\n",
    "df=news_df\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "        # Create a new row with columns\n",
    "        row_as_list = row.to_list()\n",
    "\n",
    "        # Display the item in the first column\n",
    "        print(row_as_list[1],row_as_list[2])\n",
    "        print(index)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " None,\n",
       " 'https://news.yahoo.co.jp/rss/topics/top-picks.xml',\n",
       " 'https://news.yahoo.co.jp/rss/topics/top-picks.xml',\n",
       " 'https://news.yahoo.co.jp/rss/topics/top-picks.xml',\n",
       " '']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_as_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>Type</th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>URI</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>source</td>\n",
       "      <td>@IT</td>\n",
       "      <td>https://atmarkit.itmedia.co.jp/</td>\n",
       "      <td>https://atmarkit.itmedia.co.jp/</td>\n",
       "      <td>Atmark IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>https://news.yahoo.co.jp/rss/topics/top-picks.xml</td>\n",
       "      <td>https://news.yahoo.co.jp/rss/topics/top-picks.xml</td>\n",
       "      <td>https://news.yahoo.co.jp/rss/topics/top-picks.xml</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid    Type                                              Title  \\\n",
       "0  0.0  source                                                @IT   \n",
       "1  NaN    None  https://news.yahoo.co.jp/rss/topics/top-picks.xml   \n",
       "\n",
       "                                                 URL  \\\n",
       "0                    https://atmarkit.itmedia.co.jp/   \n",
       "1  https://news.yahoo.co.jp/rss/topics/top-picks.xml   \n",
       "\n",
       "                                                 URI Description  \n",
       "0                    https://atmarkit.itmedia.co.jp/   Atmark IT  \n",
       "1  https://news.yahoo.co.jp/rss/topics/top-picks.xml              "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML or rdf\n"
     ]
    }
   ],
   "source": [
    "from xml.etree import ElementTree\n",
    "import streamlit  as st\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def extract_rss_urls(website_url):\n",
    "    response = requests.get(website_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    rss_urls = []\n",
    "    for link in soup.find_all('link', type='application/rss+xml'):\n",
    "        rss_urls.append(link.get('href'))\n",
    "\n",
    "    return rss_urls\n",
    "\n",
    "def is_valid_url(url):\n",
    "    # Regular expression to validate an HTML URL\n",
    "    url_regex = re.compile(\n",
    "        r'^(https?|ftp)://'  # http://, https://, ftp://\n",
    "        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|'  # domain...\n",
    "        r'localhost|'  # localhost...\n",
    "        r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}|'  # ...or ipv4\n",
    "        r'\\[?[A-F0-9]*:[A-F0-9:]+\\]?)'  # ...or ipv6\n",
    "        r'(?::\\d+)?'  # optional port\n",
    "        r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
    "    \n",
    "    # Check if the URL matches the pattern\n",
    "    return re.match(url_regex, url) is not None\n",
    "\n",
    "def is_xml_extension(url):\n",
    "    # Check if the URL ends with '.xml'\n",
    "    return url.lower().endswith('.xml')\n",
    "\n",
    "def is_xml_or_rdf(url):\n",
    "    # Check if the URL ends with .xml or .rdf\n",
    "    if url.lower().endswith(('.xml', '.rdf')):\n",
    "        return True\n",
    "\n",
    "# new_site_url = \"https://win-tab.net/feed/\"\n",
    "# new_site_url = \"https://pc.watch.impress.co.jp/\"\n",
    "# new_site_url='https://pc.watch.impress.co.jp/data/rss/1.0/pcw/feed.rdf'\n",
    "new_site_url=\"https://pc.watch.impress.co.jp/data/rss/1.0/pcw/feed.rdf\"\n",
    "new_site_label = \"PC\"\n",
    "\n",
    "# if is_xml_extension(new_site_url):\n",
    "#     print(\"XML\")\n",
    "# else:\n",
    "#     print(\"Not XML\")\n",
    "        \n",
    "if is_valid_url(new_site_url):\n",
    "    if is_xml_or_rdf(new_site_url):\n",
    "        print(\"XML or rdf\")\n",
    "        rss_feeds = []\n",
    "        # rss_feeds += [new_site_url, new_site_label]\n",
    "        rss_feeds.append('new_site_url')\n",
    "    else:\n",
    "        print(\"not XML or rdf\")\n",
    "        rss_feeds = extract_rss_urls(new_site_url)\n",
    "                \n",
    "        # rss_feeds = extract_rss_urls(new_site_url)\n",
    "    \n",
    "    for item in rss_feeds:\n",
    "        feed = feedparser.parse(item)\n",
    "        for entry in feed.entries:\n",
    "            if 'published' in entry:\n",
    "                print(entry.published)\n",
    "            print(entry.title)\n",
    "            print(entry.link)\n",
    "            print('---------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeds = extract_rss_urls(\"https://pc.watch.impress.co.jp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://pc.watch.impress.co.jp/data/rss/1.0/pcw/feed.rdf']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chien\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\html\\parser.py:171: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_rss_urls(\"https://pc.watch.impress.co.jp/data/rss/1.0/pcw/feed.rdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chien\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\html\\parser.py:171: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from rdflib import Graph\n",
    "\n",
    "# website_url = \"https://win-tab.net\"\n",
    "# website_url = \"https://atmarkit.itmedia.co.jp/\"\n",
    "# website_url = \"https://win-tab.net/feed/\"\n",
    "# website_url = \"https://pc.watch.impress.co.jp/\"\n",
    "website_url ='https://pc.watch.impress.co.jp/data/rss/1.0/pcw/feed.rdf'\n",
    "# website_url =\"https://pc.watch.impress.co.jp/data/rss/1.0/pcw/feed.rdf\"\n",
    "\n",
    "response = requests.get(website_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "rss_urls = []\n",
    "\n",
    "if website_url.lower().endswith(('.rdf')):\n",
    "    # Initialize the graph\n",
    "    g = Graph()\n",
    "    # Parse the RDF data from a URL or a file\n",
    "    g.parse(\"http://example.org/some-rdf-data\")\n",
    "    # Define the namespace for Dublin Core, which often contains the title\n",
    "    from rdflib.namespace import DC\n",
    "    # Query the graph for the title\n",
    "    title = None\n",
    "    for s, p, o in g:\n",
    "        if p == DC.title:\n",
    "            title = o\n",
    "            break\n",
    "\n",
    "    # Print the title\n",
    "    if title:\n",
    "        print(\"Title:\", title)\n",
    "    else:\n",
    "        print(\"Title not found.\")\n",
    "else:\n",
    "    for link in soup.find_all('link', type='application/rss+xml'):\n",
    "        rss_urls.append([link.get('title'), link.get('href')])\n",
    "        print(link.get('title'), link.get('href'))\n",
    "\n",
    "print(rss_urls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<rdf:rdf xml:lang=\"ja\" xmlns=\"http://purl.org/rss/1.0/\" xmlns:content=\"http://purl.org/rss/1.0/modules/content/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "<channel rdf:about=\"https://pc.watch.impress.co.jp/data/rss/1.0/pcw/feed.rdf\">\n",
       "<title>PC Watch</title>\n",
       "<link/>https://pc.watch.impress.co.jp\n",
       "  <description>PC/テクノロジーの総合情報サイト</description>\n",
       "<dc:language>ja</dc:language>\n",
       "<dc:rights>Copyright (c) 2015 Impress Corporation. All rights reserved.</dc:rights>\n",
       "<dc:date>2024-08-17T08:02:52+09:00</dc:date>\n",
       "<items>\n",
       "<rdf:seq>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/column/retro-game-joshi/1616377.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/column/config/1616491.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/news/1616426.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/news/1616418.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/news/1616376.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/news/streamer_watch/1616366.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/news/1616349.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/news/1616345.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/news/todays_sales/1616335.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/news/1616325.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/news/todays_sales/1616309.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/news/todays_sales/1616292.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/news/todays_sales/1616290.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/news/1616282.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/news/todays_sales/1616285.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/news/todays_sales/1616281.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/news/todays_sales/1616280.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/column/hothot/1616241.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/topic/feature/1616199.html?ref=rss\"></rdf:li>\n",
       "<rdf:li rdf:resource=\"https://pc.watch.impress.co.jp/docs/news/1616274.html?ref=rss\"></rdf:li>\n",
       "</rdf:seq>\n",
       "</items>\n",
       "</channel>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/column/retro-game-joshi/1616377.html?ref=rss\">\n",
       "<title>【インプレスeスポーツ部女子レトロゲーム班】奥村茉実、「ハイドライド3SV」に挑戦。「これ初代より難しいのでは……？」 </title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/column/retro-game-joshi/1616377.html\n",
       "  <dc:date>2024-08-17T08:00:00+09:00</dc:date>\n",
       "<dc:creator>奥村 茉実</dc:creator>\n",
       "<description><![CDATA[　みなさんこんにちは、奥村茉実です。前回無事「ハイドライド」をクリアし、今回からは新しいゲームになります！その新しいゲームとは……「ハイドライド3SV」！本来なら次は2となりそうですが、かなり難易度が高いそうなので、これはスキップすることになりました。ハイドライド3SVは、1987年に発売された元祖ハイドライド3のパワーアップバージョンです。1989年にT&amp;E SOFTから発売され、現在Project EGGにて550円で購入可能です。]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/column/config/1616491.html?ref=rss\">\n",
       "<title>【山田祥平のRe:config.sys】バッテリ事情の微妙で気になる将来 </title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/column/config/1616491.html\n",
       "  <dc:date>2024-08-17T06:17:00+09:00</dc:date>\n",
       "<dc:creator>山田 祥平</dc:creator>\n",
       "<description><![CDATA[ ]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/news/1616426.html?ref=rss\">\n",
       "<title>ドスパラ、ゲーミングPCが最大5万円オフとなる「夏のSALE第2弾」 </title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/news/1616426.html\n",
       "  <dc:date>2024-08-16T18:10:02+09:00</dc:date>\n",
       "<dc:creator>浅井 淳志</dc:creator>\n",
       "<description><![CDATA[　サードウェーブはドスパラ店舗および通販サイトにて、対象PCの購入時に使用できる最大5万円引きのクーポンを配布する「夏のSALE第2弾」を開始した。期間は店舗が8月29日閉店まで、通販サイトが8月30日10時59分まで。]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/news/1616418.html?ref=rss\">\n",
       "<title>Google AI検索結果の概要表示が日本でも利用可に </title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/news/1616418.html\n",
       "  <dc:date>2024-08-16T17:35:30+09:00</dc:date>\n",
       "<dc:creator>浅井 淳志</dc:creator>\n",
       "<description><![CDATA[　Googleは15日(米国時間)、Google検索におけるAIを活用した検索結果の概要生成機能「AI Overviews」を日本でも導入すると発表した。本機能は5月より米国などで提供が開始されており、日本のほか、イギリス、インド、インドネシア、メキシコ、ブラジルでも今後数週間で段階的に実装される。]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/news/1616376.html?ref=rss\">\n",
       "<title>サンワサプライ、サーバーやNASの収納に好適なマルチラック </title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/news/1616376.html\n",
       "  <dc:date>2024-08-16T13:58:04+09:00</dc:date>\n",
       "<dc:creator>浅井 淳志</dc:creator>\n",
       "<description><![CDATA[　サンワサプライは、サーバーやNASなどの収納に好適なマルチラックとして、高さ100cmの「CP-SVNAMULT7BK」と高さ130cmの「CP-SVNAMULT8BK」を発売した。価格は順に26万1,800円、29万4,800円。]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/news/streamer_watch/1616366.html?ref=rss\">\n",
       "<title>【やじうま配信者Watch】AVIOT、にじさんじのイブラヒムさんとコラボしたワイヤレスイヤフォン</title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/news/streamer_watch/1616366.html\n",
       "  <dc:date>2024-08-16T13:26:49+09:00</dc:date>\n",
       "<dc:creator>関根 慎一</dc:creator>\n",
       "<description><![CDATA[　AVIOTは、にじさんじ所属のVTuberイブラヒムさんをイメージしたワイヤレスイヤフォン「TE-Q3-IBR」の予約販売受付を直販サイトで15日に開始した。期間は9月16日までで価格は2万2,880円。発送は12月中旬以降。]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/news/1616349.html?ref=rss\">\n",
       "<title>なるほどそうきたか。Meta Quest 2以降でHDMI入力を可能にするアプリ </title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/news/1616349.html\n",
       "  <dc:date>2024-08-16T12:58:23+09:00</dc:date>\n",
       "<dc:creator>劉 尭</dc:creator>\n",
       "<description><![CDATA[　Metaは16日、VRヘッドセットである「Meta Quest 2/3/Pro」向けに、ほかのデバイスから低遅延でHDMI入力を可能にするアプリ「Meta Quest HDMI Link」を発表した。ただ、後述するように設定がやや複雑のため、「App Lab」でリリースする予定となっている。]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/news/1616345.html?ref=rss\">\n",
       "<title>PC上の画像をチェキでプリント。富士フイルムがWindows用ドライバ公開 </title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/news/1616345.html\n",
       "  <dc:date>2024-08-16T12:53:48+09:00</dc:date>\n",
       "<dc:creator>関根 慎一</dc:creator>\n",
       "<description><![CDATA[　富士フイルムは14日、スマホ向けモバイルプリンタ「instax Link WIDE」のWindows用プリンタドライバ「instax Link WIDE Printer Driver for Windows」を公開した。無料でダウンロードできる。]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/news/todays_sales/1616335.html?ref=rss\">\n",
       "<title>【本日みつけたお買い得品】BOSEのノイキャン搭載ワイヤレスヘッドフォンが約1万円オフのタイムセール</title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/news/todays_sales/1616335.html\n",
       "  <dc:date>2024-08-16T12:30:00+09:00</dc:date>\n",
       "<dc:creator>浅井 淳志</dc:creator>\n",
       "<description><![CDATA[　Amazonにおいて、Boseのワイヤレスヘッドフォン「QuietComfort Ultra」が23%オフの4万5,900円で購入できる。]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/news/1616325.html?ref=rss\">\n",
       "<title>Amazon限定、2万8,980円の27型WQHD液晶 </title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/news/1616325.html\n",
       "  <dc:date>2024-08-16T11:53:49+09:00</dc:date>\n",
       "<dc:creator>劉 尭</dc:creator>\n",
       "<description><![CDATA[　JAPANNEXTは、2万8,980円のWQHD(2,560×1,440ドット)表示対応27型モニター「JN-i27Q4FL-H」、2万1,980円のフルHD(1,920×1,080ドット)/200Hz表示対応27型ゲーミングモニター「JN-27V200F」をAmazon限定で発売した。]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/news/todays_sales/1616309.html?ref=rss\">\n",
       "<title>【本日みつけたお買い得品】Ryzen 7 5700U搭載のミニPCが4万円切りで販売中</title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/news/todays_sales/1616309.html\n",
       "  <dc:date>2024-08-16T11:20:30+09:00</dc:date>\n",
       "<dc:creator>劉 尭</dc:creator>\n",
       "<description><![CDATA[　GMKtecのRyzen 7 5700U搭載ミニPC「NucBox M5」が、Amazonのタイムセールにて3万9,998円で販売中となっている。]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/news/todays_sales/1616292.html?ref=rss\">\n",
       "<title>【本日みつけたお買い得品】NECのA4カラーページプリンタが最安値の2万円切りに</title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/news/todays_sales/1616292.html\n",
       "  <dc:date>2024-08-16T10:19:56+09:00</dc:date>\n",
       "<dc:creator>影山 巧</dc:creator>\n",
       "<description><![CDATA[　OCNオンラインショップ(元NTT-X Store)は、プリンタおよび複合機を対象に、会員限定の割引クーポンを配布している。NEC「Color MultiWriter 4C150」は、2,110円引きクーポンにより、価格比較サイトで最安値の1万9,980円にて購入可能だ。期限は「今だけ」。]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/news/todays_sales/1616290.html?ref=rss\">\n",
       "<title>【本日みつけたお買い得品】Type-C/A両対応のポータブルSSD 1TBが2,520円引き</title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/news/todays_sales/1616290.html\n",
       "  <dc:date>2024-08-16T10:08:04+09:00</dc:date>\n",
       "<dc:creator>影山 巧</dc:creator>\n",
       "<description><![CDATA[　Amazonにおいて、スティック型ポータブルSSDがお買い得だ。トランセンド「ESD310」シリーズのAmazon限定モデルは、直近価格からの値引きで、256GB版が972円引きの5,508円、512GB版が1,452円引きの8,228円、1TB版が2,520円引きの1万4,280円、2TB版が4,770円引きの2万7,030円にて購入できる。]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/news/1616282.html?ref=rss\">\n",
       "<title>ASUS、最速応答速度0.03msの32型4K有機ELゲーミングモニター </title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/news/1616282.html\n",
       "  <dc:date>2024-08-16T10:00:00+09:00</dc:date>\n",
       "<dc:creator>鈴木 悠斗</dc:creator>\n",
       "<description><![CDATA[　ASUSは、「Republic of Gamers」ブランドより、32型の有機ELゲーミングモニター「ROG Swift OLED PG32UCDM」を23日に発売する。16日から予約を開始し、実売予想価格は19万6,920円前後の見込み。]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/news/todays_sales/1616285.html?ref=rss\">\n",
       "<title>【本日みつけたお買い得品】Type-C搭載の240Hz/27型ゲーミングモニターが4千円引き</title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/news/todays_sales/1616285.html\n",
       "  <dc:date>2024-08-16T09:53:31+09:00</dc:date>\n",
       "<dc:creator>影山 巧</dc:creator>\n",
       "<description><![CDATA[　Amazonにおいて、MSIの27型ゲーミングモニター「G274QPX」が4,000円引きクーポンで、5万5,800円にて購入できる。]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/news/todays_sales/1616281.html?ref=rss\">\n",
       "<title>【本日みつけたお買い得品】MSIのGeForce RTX 4060ゲーミングノートが3万円オフ</title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/news/todays_sales/1616281.html\n",
       "  <dc:date>2024-08-16T09:47:07+09:00</dc:date>\n",
       "<dc:creator>影山 巧</dc:creator>\n",
       "<description><![CDATA[　Amazonにおいて、15.6型ゲーミングノートPCのMSI「Cyborg 15 A13V」が3万円引きクーポンで、15万9,800円にて購入可能だ。]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/news/todays_sales/1616280.html?ref=rss\">\n",
       "<title>【本日みつけたお買い得品】16GBメモリ/512GB SSDのN100搭載ノートが4万4,965円</title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/news/todays_sales/1616280.html\n",
       "  <dc:date>2024-08-16T09:24:27+09:00</dc:date>\n",
       "<dc:creator>影山 巧</dc:creator>\n",
       "<description><![CDATA[　Amazonにおいて、15.6型ノートPCのCHUWI「GemiBook Plus」が7,935円引きで、4万4,965円にて購入可能となっている。]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/column/hothot/1616241.html?ref=rss\">\n",
       "<title>【Hothotレビュー】重量1kg切りでCore Ultra 7搭載、AI処理もイケるマウスの14型ビジネスノート </title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/column/hothot/1616241.html\n",
       "  <dc:date>2024-08-16T06:24:00+09:00</dc:date>\n",
       "<dc:creator>松野 将太</dc:creator>\n",
       "<description><![CDATA[ ]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/topic/feature/1616199.html?ref=rss\">\n",
       "<title>光回線の代替として人気の「ホームルーター」、大手キャリア4社の速度と導入時の注意点などを比較</title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/topic/feature/1616199.html\n",
       "  <dc:date>2024-08-16T06:16:00+09:00</dc:date>\n",
       "<dc:creator>佐野 正弘</dc:creator>\n",
       "<description><![CDATA[ネット回線を簡単に開通できる5Gホームルーター。]]></description>\n",
       "</item>\n",
       "<item rdf:about=\"https://pc.watch.impress.co.jp/docs/news/1616274.html?ref=rss\">\n",
       "<title>ガチくんに! 第332回 どぐら/ストーム久保とEWC予想&amp;Chained Together </title>\n",
       "<link/>https://pc.watch.impress.co.jp/docs/news/1616274.html\n",
       "  <dc:date>2024-08-16T06:00:00+09:00</dc:date>\n",
       "<dc:creator>PC Watch編集部</dc:creator>\n",
       "<description><![CDATA[※毎週木曜日にプロ格闘ゲームプレイヤーであるガチくんをパーソナリティに迎え、ストリートファイター6攻略企画「ガチくんに!」をTwitchで配信しています。レギュラー出演者はカワノ、ぷげら、奥村茉実。ここでは当日放送したおおまかな内容を紹介するとともに、YouTubeにアップロードしたアーカイブの動画を掲載しています。]]></description>\n",
       "</item>\n",
       "</rdf:rdf>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "\n",
    "# Initialize the graph\n",
    "g = Graph()\n",
    "\n",
    "# Parse the RDF data from a URL or a file\n",
    "g.parse(\"http://example.org/some-rdf-data\")\n",
    "# g.parse(\"https://pc.watch.impress.co.jp/data/rss/1.0/pcw/feed.rdf\")\n",
    "\n",
    "# Define the namespace for Dublin Core, which often contains the title\n",
    "from rdflib.namespace import DC\n",
    "\n",
    "# Query the graph for the title\n",
    "title = None\n",
    "for s, p, o in g:\n",
    "    if p == DC.title:\n",
    "        title = o\n",
    "        break\n",
    "\n",
    "# Print the title\n",
    "if title:\n",
    "    print(\"Title:\", title)\n",
    "else:\n",
    "    print(\"Title not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title not found.\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "from rdflib.namespace import DC, DCTERMS, FOAF\n",
    "\n",
    "# Initialize the graph\n",
    "g = Graph()\n",
    "\n",
    "# Parse the RDF data from a URL\n",
    "url = \"https://pc.watch.impress.co.jp/data/rss/1.0/pcw/feed.rdf\"\n",
    "g.parse(url, format=\"xml\")\n",
    "\n",
    "# Attempt to find the title using different common namespaces\n",
    "title_predicates = [\n",
    "    DC.title,         # Dublin Core title\n",
    "    DCTERMS.title,    # Dublin Core Terms title\n",
    "    FOAF.name,        # FOAF name (sometimes used as a title)\n",
    "]\n",
    "\n",
    "title = None\n",
    "\n",
    "# Search for the title in the RDF graph\n",
    "for predicate in title_predicates:\n",
    "    for s, p, o in g.triples((None, predicate, None)):\n",
    "        title = o\n",
    "        break\n",
    "    if title:\n",
    "        break\n",
    "\n",
    "# Print the extracted title\n",
    "if title:\n",
    "    print(\"Title:\", title)\n",
    "else:\n",
    "    print(\"Title not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
